{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM/GRU_English_to_French.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "om4Kj4k8uDDD"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "\n",
        "import helper\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional, SimpleRNN, LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rMfsKyLXFDo",
        "outputId": "6d7c3b10-f068-4ab3-b89f-bcb6b375cde1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "#print(device_lib.list_local_devices())\n",
        "device_lib.list_local_devices()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7no-_Is16Wc2",
        "outputId": "a1581a2f-2ee4-4447-c0bc-d6f4f547fda0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 10373894186266952967\n",
              " xla_global_id: -1, name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 14465892352\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 16651275156050919117\n",
              " physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
              " xla_global_id: 416903419]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data source \n",
        "https://www.kaggle.com/dhruvildave/en-fr-translation-dataset <br>\n",
        "The data was separated into two.<br>\n",
        "Only a portion of the data was used."
      ],
      "metadata": {
        "id": "psctbc25hO0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "english_path = '/content/drive/MyDrive/data/training/small_vocab_en'\n",
        "french_path = '/content/drive/MyDrive/data/training/small_vocab_fr'"
      ],
      "metadata": {
        "id": "bD9otlJ5RkIM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_file = os.path.join(english_path)\n",
        "with open(input_file, \"r\") as f:\n",
        "    data = f.read()\n",
        "english_sentences = data.split('\\n')\n",
        "\n",
        "input_file = os.path.join(french_path)\n",
        "with open(input_file, \"r\") as f:\n",
        "    data = f.read()\n",
        "french_sentences = data.split('\\n')"
      ],
      "metadata": {
        "id": "f_3C5BDmRj73"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " for i in range(5):\n",
        "    print(f'English: -> {english_sentences[i]}')\n",
        "    print(f'French : -> {french_sentences[i]}' )\n",
        "    print('-----------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OQiaVCia3RD",
        "outputId": "362c3257-00c0-4aa7-afb8-e07695d1233c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English: -> new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
            "French : -> new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n",
            "-----------------------------------\n",
            "English: -> the united states is usually chilly during july , and it is usually freezing in november .\n",
            "French : -> les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .\n",
            "-----------------------------------\n",
            "English: -> california is usually quiet during march , and it is usually hot in june .\n",
            "French : -> california est généralement calme en mars , et il est généralement chaud en juin .\n",
            "-----------------------------------\n",
            "English: -> the united states is sometimes mild during june , and it is cold in september .\n",
            "French : -> les états-unis est parfois légère en juin , et il fait froid en septembre .\n",
            "-----------------------------------\n",
            "English: -> your least liked fruit is the grape , but my least liked is the apple .\n",
            "French : -> votre moins aimé fruit est le raisin , mais mon moins aimé est la pomme .\n",
            "-----------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of English words {len([i for sentence in english_sentences for i in sentence.split()])}')\n",
        "print(f'Number of French words {len([i for sentence in french_sentences for i in sentence.split()])}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvijqpFdbF5W",
        "outputId": "256ce2ae-9b13-4e05-f541-8340d64092b4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of English words 1823250\n",
            "Number of French words 1961295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_words_counter = collections.Counter([i for sentence in english_sentences for i in sentence.split()])\n",
        "french_words_counter = collections.Counter([i for sentence in french_sentences for i in sentence.split()])\n",
        "print(f'Number of UNIQUE English words {english_words_counter}')\n",
        "print(f'Number of UNIQUE English words {french_words_counter}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37hpoXrefPV5",
        "outputId": "fb5a4c74-014e-453f-ac89-24009af5eeac"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of UNIQUE English words Counter({'is': 205858, ',': 140897, '.': 129039, 'in': 75525, 'it': 75137, 'during': 74933, 'the': 67628, 'but': 63987, 'and': 59850, 'sometimes': 37746, 'usually': 37507, 'never': 37500, 'least': 27564, 'favorite': 27371, 'fruit': 27105, 'most': 14934, 'loved': 13666, 'liked': 13546, 'new': 12197, 'paris': 11334, 'india': 11277, 'united': 11270, 'states': 11270, 'california': 11250, 'jersey': 11225, 'france': 11170, 'china': 10953, 'he': 10786, 'she': 10786, 'grapefruit': 10118, 'your': 9734, 'my': 9700, 'his': 9700, 'her': 9700, 'fall': 9134, 'june': 9133, 'spring': 9102, 'january': 9090, 'winter': 9038, 'march': 9023, 'autumn': 9004, 'may': 8995, 'nice': 8984, 'september': 8958, 'july': 8956, 'april': 8954, 'november': 8951, 'summer': 8948, 'december': 8945, 'february': 8942, 'our': 8932, 'their': 8932, 'freezing': 8928, 'pleasant': 8916, 'beautiful': 8915, 'october': 8910, 'snowy': 8898, 'warm': 8890, 'cold': 8878, 'wonderful': 8808, 'dry': 8794, 'busy': 8791, 'august': 8789, 'chilly': 8770, 'rainy': 8761, 'mild': 8743, 'wet': 8726, 'relaxing': 8696, 'quiet': 8693, 'hot': 8639, 'dislikes': 7314, 'likes': 7314, 'limes': 5554, 'mangoes': 5549, 'lemons': 5533, 'grapes': 5525, 'apples': 5452, 'oranges': 5452, 'strawberries': 5452, 'bananas': 5452, 'peaches': 5451, 'pears': 5451, 'to': 5166, 'strawberry': 4715, 'grape': 4703, 'lime': 4680, 'apple': 4652, 'lemon': 4652, 'banana': 4652, 'mango': 4652, 'pear': 4652, 'peach': 4652, 'orange': 4651, 'like': 4588, 'dislike': 4444, 'they': 3222, 'that': 2712, 'i': 2664, 'we': 2532, 'you': 2414, 'animal': 2304, 'a': 1944, 'truck': 1944, 'car': 1944, 'automobile': 1944, 'was': 1867, 'next': 1666, 'go': 1386, 'driving': 1296, 'visit': 1224, 'little': 1016, 'big': 1016, 'old': 972, 'yellow': 972, 'red': 972, 'rusty': 972, 'blue': 972, 'white': 972, 'black': 972, 'green': 972, 'shiny': 972, 'favorite.': 961, 'are': 870, '?': 811, 'last': 781, 'feared': 768, 'animals': 768, 'this': 768, 'plan': 714, 'going': 666, 'saw': 648, 'disliked': 648, 'drives': 648, 'drove': 648, 'grapefruit.': 574, 'between': 540, 'liked.': 500, 'loved.': 500, 'translate': 480, 'plans': 476, 'peaches.': 393, 'pears.': 393, 'bananas.': 392, 'oranges.': 392, 'apples.': 392, 'strawberries.': 392, 'were': 384, 'went': 378, 'might': 378, 'wanted': 378, 'thinks': 360, 'grapes.': 319, 'spanish': 312, 'portuguese': 312, 'chinese': 312, 'english': 312, 'french': 312, 'lemons.': 311, 'translating': 300, 'mangoes.': 295, 'limes.': 290, 'difficult': 260, 'fun': 260, 'easy': 260, 'wants': 252, 'think': 240, 'why': 240, \"it's\": 240, 'did': 204, 'orange.': 197, 'mango.': 196, 'banana.': 196, 'peach.': 196, 'lemon.': 196, 'pear.': 196, 'apple.': 196, 'cat': 192, 'shark': 192, 'bird': 192, 'mouse': 192, 'horse': 192, 'elephant': 192, 'dog': 192, 'monkey': 192, 'lion': 192, 'bear': 192, 'rabbit': 192, 'snake': 192, 'lime.': 168, 'grape.': 145, 'when': 144, 'strawberry.': 133, 'want': 126, 'fruit.': 87, 'do': 84, 'how': 67, 'elephants': 64, 'horses': 64, 'dogs': 64, 'sharks': 64, 'snakes': 64, 'cats': 64, 'rabbits': 64, 'monkeys': 64, 'bears': 64, 'birds': 64, 'lions': 64, 'mice': 64, \"didn't\": 60, 'eiffel': 57, 'tower': 57, 'grocery': 57, 'store': 57, 'football': 57, 'field': 57, 'lake': 57, 'school': 57, 'would': 48, \"aren't\": 36, 'been': 36, 'weather': 33, 'does': 24, 'has': 24, \"isn't\": 24, 'am': 24, 'where': 12, 'have': 12})\n",
            "Number of UNIQUE English words Counter({'est': 196809, '.': 135619, ',': 123135, 'en': 105768, 'il': 84079, 'les': 65255, 'mais': 63987, 'et': 59851, 'la': 49861, 'parfois': 37746, 'jamais': 37215, 'le': 35306, \"l'\": 32917, 'généralement': 31292, 'moins': 27557, 'au': 25738, 'aimé': 24842, 'fruit': 23626, 'préféré': 22886, 'agréable': 17751, 'froid': 16794, 'son': 16496, 'chaud': 16405, 'de': 15070, 'plus': 14934, 'automne': 14727, 'mois': 14350, 'à': 13870, 'elle': 12056, 'citrons': 11679, 'paris': 11334, 'inde': 11277, 'états-unis': 11210, 'france': 11170, 'jersey': 11052, 'new': 11047, 'chine': 10936, 'pendant': 10741, 'pamplemousse': 10140, 'mon': 9403, 'votre': 9368, 'juin': 9133, 'printemps': 9100, 'janvier': 9090, 'hiver': 9038, 'mars': 9023, 'été': 8999, 'mai': 8995, 'septembre': 8958, 'juillet': 8956, 'avril': 8954, 'novembre': 8951, 'décembre': 8945, 'février': 8942, 'octobre': 8911, 'aime': 8870, 'août': 8789, 'merveilleux': 8704, 'relaxant': 8458, 'doux': 8458, 'humide': 8446, 'notre': 8319, 'californie': 8189, 'sec': 7957, 'leur': 7855, 'occupé': 7782, 'pluvieux': 7658, 'calme': 7256, 'beau': 6387, 'habituellement': 6215, 'pommes': 5844, 'pêches': 5844, 'oranges': 5844, 'poires': 5844, 'fraises': 5844, 'bananes': 5844, 'verts': 5835, 'raisins': 5780, 'mangues': 5774, \"d'\": 5100, 'mangue': 4899, 'gel': 4886, 'raisin': 4852, 'pomme': 4848, \"l'orange\": 4848, 'citron': 4848, 'chaux': 4848, 'banane': 4848, 'poire': 4848, 'fraise': 4848, 'pêche': 4848, 'pas': 4495, 'enneigée': 4008, 'favori': 3857, 'déteste': 3743, 'gèle': 3622, 'fruits': 3566, 'voiture': 3510, \"l'automne\": 3411, 'ils': 3185, \"n'aime\": 3131, 'california': 3061, 'neige': 3016, 'fait': 2916, 'belle': 2726, 'ne': 2715, 'nous': 2520, 'vous': 2517, 'des': 2435, 'animal': 2248, 'camion': 1944, 'cours': 1927, 'neigeux': 1867, 'conduit': 1706, 'prochain': 1666, 'je': 1548, 'ce': 1465, 'tranquille': 1437, 'a': 1356, 'cher': 1308, 'une': 1278, 'cette': 1239, 'était': 1198, 'aller': 1180, 'chaude': 1124, 'aiment': 1116, 'aimons': 1111, \"n'aiment\": 1111, \"n'aimez\": 1094, 'leurs': 1072, 'aimez': 1053, 'sont': 1018, 'aimé.': 1010, 'détestons': 1001, 'jaune': 972, 'rouge': 972, \"j'aime\": 966, 'visiter': 908, 'sèche': 837, 'occupée': 836, 'frisquet': 834, '?': 811, 'préférée': 770, 'animaux': 768, 'dernier': 757, 'aimait': 707, 'un': 698, 'conduisait': 673, 'que': 667, 'nouvelle': 648, 'vieille': 647, 'vu': 645, 'verte': 628, 'petite': 615, 'nos': 613, 'noire': 602, 'brillant': 587, 'blanche': 579, 'redouté': 576, 'pleut': 562, \"n'aimait\": 561, 'pamplemousses': 552, 'pense': 540, 'entre': 540, 'bleue': 504, 'nouveau': 502, 'traduire': 501, 'rouillée': 486, 'bleu': 468, 'se': 461, 'grande': 459, 'rouillé': 454, 'préféré.': 419, 'ses': 402, \"qu'il\": 393, 'blanc': 393, 'aux': 392, 'brillante': 385, 'préférés': 383, 'noir': 370, 'pluies': 367, 'envisage': 360, 'étaient': 357, 'va': 355, 'rendre': 350, 'vert': 344, '-': 328, 'vieux': 325, 'petit': 324, 'espagnol': 312, 'portugais': 312, 'chinois': 312, 'anglais': 312, 'français': 312, 'glaciales': 307, 'mes': 297, 'cet': 286, 'automobile': 278, 'traduction': 277, 'mouillé': 273, 'difficile': 260, 'amusant': 260, 'facile': 260, 'comme': 259, 'gros': 258, 'souris': 256, 'pourrait': 252, 'voulait': 252, 'veut': 252, 'pourquoi': 240, 'aimés': 237, 'prévois': 233, 'prévoyons': 232, 'vos': 225, 'intention': 206, 'clémentes': 200, 'ont': 194, 'chat': 192, 'requin': 192, 'cheval': 192, 'chien': 192, 'singe': 192, 'lion': 192, 'ours': 192, 'lapin': 192, 'serpent': 192, 'redoutés': 190, 'allé': 187, 'grosse': 185, 'pluie': 174, 'trop': 173, 'monde': 173, 'maillot': 173, 'vont': 168, 'volant': 165, 'avez': 162, 'i': 150, 'allés': 150, 'allée': 150, 'quand': 144, 'oiseau': 128, 'éléphant': 128, 'pourraient': 126, 'voulaient': 126, 'veulent': 126, 'détendre': 111, 'aimée': 105, 'magnifique': 104, \"l'automobile\": 100, \"n'aimons\": 97, '-ce': 95, 'gelé': 94, 'détestait': 87, 'grand': 81, 'bien': 77, 'vers': 76, 'prévoient': 75, 'prévoit': 75, 'lui': 70, 'visite': 68, 'comment': 67, 'éléphants': 64, 'chevaux': 64, 'chiens': 64, \"l'éléphant\": 64, \"l'oiseau\": 64, 'requins': 64, \"l'ours\": 64, 'serpents': 64, 'chats': 64, 'lapins': 64, 'singes': 64, 'oiseaux': 64, 'lions': 64, 'légère': 63, 'cépage': 60, 'pensez': 60, 'États-unis': 57, 'tour': 57, 'eiffel': 57, \"l'épicerie\": 57, 'terrain': 57, 'football': 57, 'lac': 57, \"l'école\": 57, \"l'animal\": 56, \"n'est\": 47, 'allons': 45, 'allez': 45, 'peu': 41, 'pousse': 41, 'du': 39, '-il': 36, 'temps': 33, 'at': 32, 'rouille': 32, 'sur': 28, \"qu'elle\": 26, '-ils': 26, 'petites': 26, '-elle': 24, 'dernière': 24, 'êtes-vous': 24, 'vais': 24, 'voudrait': 24, 'proches': 20, 'frais': 20, 'manguiers': 19, 'avons': 19, 't': 18, 'porcelaine': 17, 'détestez': 17, \"c'est\": 17, 'grandes': 16, 'préférées': 16, 'douce': 14, 'durant': 14, 'congélation': 14, 'plaît': 13, 'où': 12, 'dans': 12, 'est-ce': 12, 'voulez': 12, 'aimeraient': 12, \"n'a\": 12, 'petits': 10, 'aiment-ils': 10, 'grands': 9, 'limes': 9, 'envisagent': 9, 'grosses': 8, 'bénigne': 8, 'mouillée': 7, 'enneigé': 7, 'moindres': 7, 'conduite': 6, 'gelés': 5, 'tout': 4, 'etats-unis': 3, \"n'êtes\": 3, 'vit': 3, 'ressort': 2, 'détend': 2, 'redoutée': 2, 'qui': 2, 'traduis': 2, 'apprécié': 2, 'allions': 1, 'trouvé': 1, 'as-tu': 1, 'faire': 1, 'favoris': 1, 'souvent': 1, 'es-tu': 1, 'moteur': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'15 Most common words in English:{list(zip(*english_words_counter.most_common(15)))[0]}')\n",
        "print(f'15 Most common words in French:{list(zip(*french_words_counter.most_common(15)))[0]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IddHkwb1dFR9",
        "outputId": "29c1eb8c-f04e-4806-d915-a12928a07892"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15 Most common words in English:('is', ',', '.', 'in', 'it', 'during', 'the', 'but', 'and', 'sometimes', 'usually', 'never', 'least', 'favorite', 'fruit')\n",
            "15 Most common words in French:('est', '.', ',', 'en', 'il', 'les', 'mais', 'et', 'la', 'parfois', 'jamais', 'le', \"l'\", 'généralement', 'moins')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del english_words_counter\n",
        "del french_words_counter"
      ],
      "metadata": {
        "id": "Er_yZa_0nKHx"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "    x_tk = Tokenizer()\n",
        "    x_tk.fit_on_texts(text)\n",
        "    return x_tk.texts_to_sequences(text), x_tk\n",
        "\n",
        "text_sentences = [\n",
        "    'There was a monkey on the tree',\n",
        "    'The banana was on the ground.',\n",
        "    'sky is blue, SKY.']\n",
        "\n",
        "text_tokenized, text_tokenizer = tokenize(text_sentences)\n",
        "print(f'Tonkenizer ids  :{text_tokenized}\\n(token_id, word):{text_tokenizer.word_index}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwXG4llilItM",
        "outputId": "b7f93dfe-2962-46cb-e6af-0cb1be3dc8a2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tonkenizer ids  :[[5, 2, 6, 7, 3, 1, 8], [1, 9, 2, 3, 1, 10], [4, 11, 12, 4]]\n",
            "(token_id, word):{'the': 1, 'was': 2, 'on': 3, 'sky': 4, 'there': 5, 'a': 6, 'monkey': 7, 'tree': 8, 'banana': 9, 'ground': 10, 'is': 11, 'blue': 12}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def padding(texts, max_length = None):\n",
        "    if max_length is None:\n",
        "        max_length = max([len(i) for i in texts])\n",
        "    return pad_sequences(texts,  padding=\"post\", maxlen=max_length)\n",
        "\n",
        "padding_test = padding(text_tokenized)\n",
        "print('Map:',text_tokenizer.word_index)\n",
        "for i, (token, pad) in enumerate(zip(text_tokenized, padding_test)):\n",
        "    print('-------')\n",
        "    print(f'Text:   {text_sentences[i]} - LENGTH:{len(text_sentences[i].split())}')\n",
        "    print(f'Input:  {np.array(token)} - LENGTH:{len(np.array(token))}')\n",
        "    print(f'Output: {pad} - LENGTH:{len(pad)}')\n",
        "    print(f'padding length: {len(pad)-len(np.array(token))}')\n",
        "\n",
        "del text_sentences\n",
        "del padding_test\n",
        "del text_tokenized\n",
        "del text_tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UpaWJi3oHju",
        "outputId": "364491e6-2384-4add-ca59-7145e01e76f6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Map: {'the': 1, 'was': 2, 'on': 3, 'sky': 4, 'there': 5, 'a': 6, 'monkey': 7, 'tree': 8, 'banana': 9, 'ground': 10, 'is': 11, 'blue': 12}\n",
            "-------\n",
            "Text:   There was a monkey on the tree - LENGTH:7\n",
            "Input:  [5 2 6 7 3 1 8] - LENGTH:7\n",
            "Output: [5 2 6 7 3 1 8] - LENGTH:7\n",
            "padding length: 0\n",
            "-------\n",
            "Text:   The banana was on the ground. - LENGTH:6\n",
            "Input:  [ 1  9  2  3  1 10] - LENGTH:6\n",
            "Output: [ 1  9  2  3  1 10  0] - LENGTH:7\n",
            "padding length: 1\n",
            "-------\n",
            "Text:   sky is blue, SKY. - LENGTH:4\n",
            "Input:  [ 4 11 12  4] - LENGTH:4\n",
            "Output: [ 4 11 12  4  0  0  0] - LENGTH:7\n",
            "padding length: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(Feature, Label):\n",
        "    preprocess_Feature, Feature_tk = tokenize(Feature)\n",
        "    preprocess_Label, Label_tk = tokenize(Label)\n",
        "\n",
        "    preprocess_Feature = padding(preprocess_Feature)\n",
        "    preprocess_Label = padding(preprocess_Label)\n",
        "\n",
        "    preprocess_Label = preprocess_Label.reshape(*preprocess_Label.shape, 1)\n",
        "\n",
        "    return preprocess_Feature, preprocess_Label, Feature_tk, Label_tk\n",
        "\n",
        "preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer = preprocess(english_sentences, french_sentences)"
      ],
      "metadata": {
        "id": "uLsAWUuDpkea"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ids_to_text(logits, tokenizer):\n",
        "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
        "    index_to_words[0] = '<PAD>'\n",
        "\n",
        "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])"
      ],
      "metadata": {
        "id": "N1yeSly9L3UE"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_english_sequence_length = preproc_english_sentences.shape[1]\n",
        "max_french_sequence_length = preproc_french_sentences.shape[1]\n",
        "\n",
        "english_vocab_size = len(english_tokenizer.word_index)\n",
        "french_vocab_size = len(french_tokenizer.word_index)"
      ],
      "metadata": {
        "id": "jOtKln3dtBSL"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Preprocessed Data summary')\n",
        "print(f\"Max English sentence:{max_english_sequence_length}\")\n",
        "print(f\"Max French sentence:{max_french_sequence_length}\")\n",
        "print(f\"English vocab size:{english_vocab_size}\")\n",
        "print(f\"French vocab size:{french_vocab_size}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X75FqImetT9n",
        "outputId": "c18bcdf0-099b-43c4-d1f6-9a46e0564676"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed Data summary\n",
            "Max English sentence:15\n",
            "Max French sentence:21\n",
            "English vocab size:199\n",
            "French vocab size:344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def MODEL(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
        "    \n",
        "    learning_rate = 1e-3\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=english_vocab_size + 1, output_dim=64, input_length=output_sequence_length, input_shape=input_shape[1:]))\n",
        "    model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
        "    model.add(Dense(french_vocab_size, activation='softmax'))\n",
        "\n",
        "    model.compile(loss=sparse_categorical_crossentropy,\n",
        "                  optimizer=Adam(learning_rate),\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "0ow7I6X3trau"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ENGLISH = padding(preproc_english_sentences, max_french_sequence_length)\n",
        "trained_model_ = MODEL( ENGLISH.shape, max_french_sequence_length, english_vocab_size, french_vocab_size)\n",
        "trained_model_.fit(ENGLISH, preproc_french_sentences, batch_size=32, epochs=10, validation_split=0.2)"
      ],
      "metadata": {
        "id": "WExVBt7J5NGW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c00ff77b-3159-46e6-d468-eccc33b237ba"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3447/3447 [==============================] - 36s 10ms/step - loss: 0.7247 - accuracy: 0.8135 - val_loss: nan - val_accuracy: 0.9247\n",
            "Epoch 2/10\n",
            "3447/3447 [==============================] - 33s 10ms/step - loss: 0.1735 - accuracy: 0.9454 - val_loss: nan - val_accuracy: 0.9583\n",
            "Epoch 3/10\n",
            "3447/3447 [==============================] - 33s 10ms/step - loss: 0.1122 - accuracy: 0.9645 - val_loss: nan - val_accuracy: 0.9668\n",
            "Epoch 4/10\n",
            "3447/3447 [==============================] - 35s 10ms/step - loss: 0.0862 - accuracy: 0.9727 - val_loss: nan - val_accuracy: 0.9725\n",
            "Epoch 5/10\n",
            "3447/3447 [==============================] - 34s 10ms/step - loss: 0.0716 - accuracy: 0.9771 - val_loss: nan - val_accuracy: 0.9750\n",
            "Epoch 6/10\n",
            "3447/3447 [==============================] - 33s 10ms/step - loss: 0.0622 - accuracy: 0.9801 - val_loss: nan - val_accuracy: 0.9779\n",
            "Epoch 7/10\n",
            "3447/3447 [==============================] - 33s 10ms/step - loss: 0.0552 - accuracy: 0.9823 - val_loss: nan - val_accuracy: 0.9783\n",
            "Epoch 8/10\n",
            "3447/3447 [==============================] - 34s 10ms/step - loss: 0.0499 - accuracy: 0.9839 - val_loss: nan - val_accuracy: 0.9797\n",
            "Epoch 9/10\n",
            "3447/3447 [==============================] - 34s 10ms/step - loss: 0.0456 - accuracy: 0.9852 - val_loss: nan - val_accuracy: 0.9811\n",
            "Epoch 10/10\n",
            "3447/3447 [==============================] - 34s 10ms/step - loss: 0.0418 - accuracy: 0.9864 - val_loss: nan - val_accuracy: 0.9802\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f22f2fc7a50>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = 54321\n",
        "print(\"ORIGINAL English: --> \", english_sentences[:index][-1])\n",
        "print('--- --- ---')\n",
        "print(\"MODEL to French:  --> \", ids_to_text(trained_model_.predict(ENGLISH[index-1:index])[0], french_tokenizer).replace('<PAD>',''))\n",
        "print(\"GOOGLE to French: -->  la france est pluvieuse en automne , et il n'y a jamais de monde en décembre\")\n",
        "print('--- --- ---')\n",
        "print('MODEL FRENCH to English using google  --> France is rainy in the fall and it is never busy in December')\n",
        "print('GOOGLE FRENCH to English using google --> France is rainy in autumn, and there are never many people in December')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9M7YPdiS4be",
        "outputId": "f94d7616-8e58-4262-fa78-fad19dd40cdf"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORIGINAL English: -->  france is rainy during fall , and it is never busy in december .\n",
            "--- --- ---\n",
            "MODEL to French:  -->  france est pluvieux pendant l' automne et il est jamais occupé en décembre        \n",
            "GOOGLE to French: -->  la france est pluvieuse en automne , et il n'y a jamais de monde en décembre\n",
            "--- --- ---\n",
            "MODEL FRENCH to English using google  --> France is rainy in the fall and it is never busy in December\n",
            "GOOGLE FRENCH to English using google --> France is rainy in autumn, and there are never many people in December\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CssehaReaR1j"
      },
      "execution_count": 35,
      "outputs": []
    }
  ]
}